{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining and NLP\n",
    "\n",
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Goal**: to internalize the steps, challenges, and methodology of text mining\n",
    "- explore text analysis by hand\n",
    "- apply text mining steps in Jupyter with Python libraries NLTK\n",
    "- classify documents correctly\n",
    "<br/>\n",
    "^ This last step will require modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import string, re\n",
    "import urllib\n",
    "\n",
    "url_a = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/A.txt\"\n",
    "url_b = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/D.txt\"\n",
    "article_a = urllib.request.urlopen(url_a).read()\n",
    "article_a_st = article_a.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "arta_tokens_raw = nltk.regexp_tokenize(article_a_st, pattern)\n",
    "\n",
    "# lower case\n",
    "arta_tokens = [i.lower() for i in arta_tokens_raw]\n",
    "\n",
    "# stop words\n",
    "nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "arta_tokens_stopped = [w for w in arta_tokens if not w in stop_words]\n",
    "\n",
    "# stem words\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "arta_stemmed = [stemmer.stem(word) for word in arta_tokens_stopped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat w second article\n",
    "article_b = urllib.request.urlopen(url_b).read()\n",
    "article_b_st = article_b.decode(\"utf-8\")\n",
    "artb_tokens_raw = nltk.regexp_tokenize(article_b_st, pattern)\n",
    "artb_tokens = [i.lower() for i in artb_tokens_raw]\n",
    "artb_tokens_stopped = [w for w in artb_tokens if not w in stop_words]\n",
    "artb_stemmed = [stemmer.stem(word) for word in artb_tokens_stopped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency (TF)\n",
    "\n",
    "$\\begin{align}\n",
    " tf_{i,j} = \\dfrac{n_{i,j}}{\\displaystyle \\sum_k n_{i,j} }\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "$\\begin{align}\n",
    "idf(w) = \\log \\dfrac{N}{df_t}\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF score\n",
    "\n",
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing } i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BNP leader Nick Griffin arrested\\n\\nThe leader of the British National Party has been arrested as part of a police inquiry following the screening of a BBC documentary.\\n\\nA party spokesman said Nick Griffin was arrested on Tuesday morning on suspicion of incitement to commit racial hatred. West Yorkshire police confirmed they had arrested a 45-year-old man from outside their area. BNP founding chairman John Tyndall was arrested on Sunday on the same charge.\\n\\nIn July, the BBC documentary Secret Agent featured covertly-filmed footage of BNP activists. Mr Griffin is the twelfth man to be arrested following the documentary. Nine men from West Yorkshire and another man from Leicester have been arrested and freed on bail. Seven of the men had been held variously in connection with suspected racially aggravated public order offences, conspiracy to commit criminal damage and possession of a firearm. Two men, both from Keighley, were arrested in September on suspicion of conspiracy to commit criminal damage. A 24-year-old man from Leicester was detained on Monday on suspicion of incitement to commit racial hatred. A BNP spokesperson said Mr Tyndall, from Brighton, was arrested following a speech he made in Burnley, Lancashire, and was released on police bail.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_b_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSet = set(arta_stemmed).union(set(artb_stemmed)) \n",
    "wordDictA = dict.fromkeys(wordSet, 0) \n",
    "wordDictB = dict.fromkeys(wordSet, 0) \n",
    "\n",
    "for word in arta_stemmed: \n",
    "    wordDictA[word]+=1\n",
    "    \n",
    "for word in artb_stemmed: \n",
    "    wordDictB[word]+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 1,\n",
       " 'bnp': 0,\n",
       " 'commit': 0,\n",
       " 'bbc': 0,\n",
       " 'juli': 0,\n",
       " 'conspiraci': 0,\n",
       " 'gain': 1,\n",
       " 'put': 1,\n",
       " 'hold': 1,\n",
       " 'us': 3,\n",
       " 'intend': 1,\n",
       " 'start': 1,\n",
       " 'brighton': 0,\n",
       " 'propos': 2,\n",
       " 'inquiri': 0,\n",
       " 'covert': 0,\n",
       " 'draft': 3,\n",
       " 'men': 0,\n",
       " 'lancashir': 0,\n",
       " 'arrest': 0,\n",
       " 'detain': 0,\n",
       " 'leader': 0,\n",
       " 'agent': 0,\n",
       " 'chairman': 0,\n",
       " 'bring': 1,\n",
       " 'model': 1,\n",
       " 'nation': 1,\n",
       " 'comput': 4,\n",
       " 'achiev': 1,\n",
       " 'meet': 1,\n",
       " 'pressur': 1,\n",
       " 'hatr': 0,\n",
       " 'poland': 1,\n",
       " 'support': 2,\n",
       " 'john': 0,\n",
       " 'septemb': 0,\n",
       " 'british': 0,\n",
       " 'reject': 1,\n",
       " 'bail': 0,\n",
       " 'click': 1,\n",
       " 'burnley': 0,\n",
       " 'compani': 1,\n",
       " 'leicest': 0,\n",
       " 'griffin': 0,\n",
       " 'new': 2,\n",
       " 'welcom': 1,\n",
       " 'sunday': 0,\n",
       " 'crimin': 0,\n",
       " 'freed': 0,\n",
       " 'lead': 1,\n",
       " 'seven': 0,\n",
       " 'screen': 0,\n",
       " 'parti': 0,\n",
       " 'sourc': 1,\n",
       " 'area': 0,\n",
       " 'part': 0,\n",
       " 'develop': 1,\n",
       " 'rule': 1,\n",
       " 'issu': 1,\n",
       " 'base': 2,\n",
       " 'larger': 1,\n",
       " 'mep': 2,\n",
       " 'activist': 0,\n",
       " 'west': 0,\n",
       " 'field': 1,\n",
       " 'direct': 4,\n",
       " 'union': 1,\n",
       " 'amazon': 1,\n",
       " 'committe': 2,\n",
       " 'suspicion': 0,\n",
       " 'could': 3,\n",
       " 'fight': 1,\n",
       " 'documentari': 0,\n",
       " 'confirm': 0,\n",
       " 'rewrit': 1,\n",
       " 'order': 2,\n",
       " 'racial': 0,\n",
       " 'incit': 0,\n",
       " 'court': 1,\n",
       " 'decis': 1,\n",
       " 'happen': 1,\n",
       " 'protect': 2,\n",
       " 'servic': 1,\n",
       " 'hurt': 1,\n",
       " 'charg': 0,\n",
       " 'effect': 1,\n",
       " 'yorkshir': 0,\n",
       " 'say': 3,\n",
       " 'impact': 1,\n",
       " 'offer': 1,\n",
       " 'secret': 0,\n",
       " 'said': 2,\n",
       " 'submit': 1,\n",
       " 'line': 1,\n",
       " 'implic': 1,\n",
       " 'intens': 1,\n",
       " 'keighley': 0,\n",
       " 'lobbi': 1,\n",
       " 'give': 1,\n",
       " 'adopt': 1,\n",
       " 'serv': 1,\n",
       " 'even': 1,\n",
       " 'old': 0,\n",
       " 'anoth': 0,\n",
       " 'nick': 0,\n",
       " 'legal': 3,\n",
       " 'busi': 1,\n",
       " 'larg': 1,\n",
       " 'play': 1,\n",
       " 'morn': 0,\n",
       " 'debat': 1,\n",
       " 'controversi': 1,\n",
       " 'various': 0,\n",
       " 'suffer': 1,\n",
       " 'possess': 0,\n",
       " 'two': 2,\n",
       " 'spokesperson': 0,\n",
       " 'offenc': 0,\n",
       " 'back': 2,\n",
       " 'read': 1,\n",
       " 'twelfth': 0,\n",
       " 'damag': 0,\n",
       " 'favour': 1,\n",
       " 'current': 1,\n",
       " 'exampl': 1,\n",
       " 'would': 3,\n",
       " 'vote': 1,\n",
       " 'largest': 1,\n",
       " 'parliament': 2,\n",
       " 'program': 1,\n",
       " 'reboot': 1,\n",
       " 'europ': 1,\n",
       " 'firearm': 0,\n",
       " 'monday': 0,\n",
       " 'vocal': 1,\n",
       " 'nine': 0,\n",
       " 'small': 2,\n",
       " 'connect': 0,\n",
       " 'might': 1,\n",
       " 'patent': 5,\n",
       " 'com': 1,\n",
       " 'law': 5,\n",
       " 'suspect': 0,\n",
       " 'releas': 0,\n",
       " 'european': 2,\n",
       " 'eu': 4,\n",
       " 'polic': 0,\n",
       " 'abstain': 1,\n",
       " 'let': 1,\n",
       " 'found': 0,\n",
       " 'chanc': 1,\n",
       " 'featur': 0,\n",
       " 'mean': 1,\n",
       " 'without': 1,\n",
       " 'setback': 1,\n",
       " 'aggrav': 0,\n",
       " 'year': 0,\n",
       " 'permit': 1,\n",
       " 'mr': 0,\n",
       " 'tyndal': 0,\n",
       " 'man': 0,\n",
       " 'concern': 1,\n",
       " 'implement': 2,\n",
       " 'commiss': 1,\n",
       " 'method': 1,\n",
       " 'shop': 1,\n",
       " 'speech': 0,\n",
       " 'similar': 1,\n",
       " 'juri': 2,\n",
       " 'internet': 1,\n",
       " 'follow': 0,\n",
       " 'one': 3,\n",
       " 'open': 1,\n",
       " 'financi': 1,\n",
       " 'state': 2,\n",
       " 'spokesman': 0,\n",
       " 'held': 0,\n",
       " 'affair': 1,\n",
       " 'oppon': 1,\n",
       " 'momentum': 1,\n",
       " 'invent': 5,\n",
       " 'film': 0,\n",
       " 'twice': 1,\n",
       " 'govern': 1,\n",
       " 'softwar': 3,\n",
       " 'made': 0,\n",
       " 'fear': 1,\n",
       " 'fail': 1,\n",
       " 'word': 1,\n",
       " 'critic': 2,\n",
       " 'ineffici': 1,\n",
       " 'use': 1,\n",
       " 'fuller': 1,\n",
       " 'member': 2,\n",
       " 'immens': 1,\n",
       " 'public': 0,\n",
       " 'first': 1,\n",
       " 'tuesday': 0,\n",
       " 'footag': 0,\n",
       " 'firm': 2,\n",
       " 'month': 1,\n",
       " 'innov': 1,\n",
       " 'outsid': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 0,\n",
       " 'bnp': 4,\n",
       " 'commit': 4,\n",
       " 'bbc': 2,\n",
       " 'juli': 1,\n",
       " 'conspiraci': 2,\n",
       " 'gain': 0,\n",
       " 'put': 0,\n",
       " 'hold': 0,\n",
       " 'us': 0,\n",
       " 'intend': 0,\n",
       " 'start': 0,\n",
       " 'brighton': 1,\n",
       " 'propos': 0,\n",
       " 'inquiri': 1,\n",
       " 'covert': 1,\n",
       " 'draft': 0,\n",
       " 'men': 3,\n",
       " 'lancashir': 1,\n",
       " 'arrest': 9,\n",
       " 'detain': 1,\n",
       " 'leader': 2,\n",
       " 'agent': 1,\n",
       " 'chairman': 1,\n",
       " 'bring': 0,\n",
       " 'model': 0,\n",
       " 'nation': 1,\n",
       " 'comput': 0,\n",
       " 'achiev': 0,\n",
       " 'meet': 0,\n",
       " 'pressur': 0,\n",
       " 'hatr': 2,\n",
       " 'poland': 0,\n",
       " 'support': 0,\n",
       " 'john': 1,\n",
       " 'septemb': 1,\n",
       " 'british': 1,\n",
       " 'reject': 0,\n",
       " 'bail': 2,\n",
       " 'click': 0,\n",
       " 'burnley': 1,\n",
       " 'compani': 0,\n",
       " 'leicest': 2,\n",
       " 'griffin': 3,\n",
       " 'new': 0,\n",
       " 'welcom': 0,\n",
       " 'sunday': 1,\n",
       " 'crimin': 2,\n",
       " 'freed': 1,\n",
       " 'lead': 0,\n",
       " 'seven': 1,\n",
       " 'screen': 1,\n",
       " 'parti': 2,\n",
       " 'sourc': 0,\n",
       " 'area': 1,\n",
       " 'part': 1,\n",
       " 'develop': 0,\n",
       " 'rule': 0,\n",
       " 'issu': 0,\n",
       " 'base': 0,\n",
       " 'larger': 0,\n",
       " 'mep': 0,\n",
       " 'activist': 1,\n",
       " 'west': 2,\n",
       " 'field': 0,\n",
       " 'direct': 0,\n",
       " 'union': 0,\n",
       " 'amazon': 0,\n",
       " 'committe': 0,\n",
       " 'suspicion': 3,\n",
       " 'could': 0,\n",
       " 'fight': 0,\n",
       " 'documentari': 3,\n",
       " 'confirm': 1,\n",
       " 'rewrit': 0,\n",
       " 'order': 1,\n",
       " 'racial': 3,\n",
       " 'incit': 2,\n",
       " 'court': 0,\n",
       " 'decis': 0,\n",
       " 'happen': 0,\n",
       " 'protect': 0,\n",
       " 'servic': 0,\n",
       " 'hurt': 0,\n",
       " 'charg': 1,\n",
       " 'effect': 0,\n",
       " 'yorkshir': 2,\n",
       " 'say': 0,\n",
       " 'impact': 0,\n",
       " 'offer': 0,\n",
       " 'secret': 1,\n",
       " 'said': 2,\n",
       " 'submit': 0,\n",
       " 'line': 0,\n",
       " 'implic': 0,\n",
       " 'intens': 0,\n",
       " 'keighley': 1,\n",
       " 'lobbi': 0,\n",
       " 'give': 0,\n",
       " 'adopt': 0,\n",
       " 'serv': 0,\n",
       " 'even': 0,\n",
       " 'old': 2,\n",
       " 'anoth': 1,\n",
       " 'nick': 2,\n",
       " 'legal': 0,\n",
       " 'busi': 0,\n",
       " 'larg': 0,\n",
       " 'play': 0,\n",
       " 'morn': 1,\n",
       " 'debat': 0,\n",
       " 'controversi': 0,\n",
       " 'various': 1,\n",
       " 'suffer': 0,\n",
       " 'possess': 1,\n",
       " 'two': 1,\n",
       " 'spokesperson': 1,\n",
       " 'offenc': 1,\n",
       " 'back': 0,\n",
       " 'read': 0,\n",
       " 'twelfth': 1,\n",
       " 'damag': 2,\n",
       " 'favour': 0,\n",
       " 'current': 0,\n",
       " 'exampl': 0,\n",
       " 'would': 0,\n",
       " 'vote': 0,\n",
       " 'largest': 0,\n",
       " 'parliament': 0,\n",
       " 'program': 0,\n",
       " 'reboot': 0,\n",
       " 'europ': 0,\n",
       " 'firearm': 1,\n",
       " 'monday': 1,\n",
       " 'vocal': 0,\n",
       " 'nine': 1,\n",
       " 'small': 0,\n",
       " 'connect': 1,\n",
       " 'might': 0,\n",
       " 'patent': 0,\n",
       " 'com': 0,\n",
       " 'law': 0,\n",
       " 'suspect': 1,\n",
       " 'releas': 1,\n",
       " 'european': 0,\n",
       " 'eu': 0,\n",
       " 'polic': 3,\n",
       " 'abstain': 0,\n",
       " 'let': 0,\n",
       " 'found': 1,\n",
       " 'chanc': 0,\n",
       " 'featur': 1,\n",
       " 'mean': 0,\n",
       " 'without': 0,\n",
       " 'setback': 0,\n",
       " 'aggrav': 1,\n",
       " 'year': 2,\n",
       " 'permit': 0,\n",
       " 'mr': 2,\n",
       " 'tyndal': 2,\n",
       " 'man': 4,\n",
       " 'concern': 0,\n",
       " 'implement': 0,\n",
       " 'commiss': 0,\n",
       " 'method': 0,\n",
       " 'shop': 0,\n",
       " 'speech': 1,\n",
       " 'similar': 0,\n",
       " 'juri': 0,\n",
       " 'internet': 0,\n",
       " 'follow': 3,\n",
       " 'one': 0,\n",
       " 'open': 0,\n",
       " 'financi': 0,\n",
       " 'state': 0,\n",
       " 'spokesman': 1,\n",
       " 'held': 1,\n",
       " 'affair': 0,\n",
       " 'oppon': 0,\n",
       " 'momentum': 0,\n",
       " 'invent': 0,\n",
       " 'film': 1,\n",
       " 'twice': 0,\n",
       " 'govern': 0,\n",
       " 'softwar': 0,\n",
       " 'made': 1,\n",
       " 'fear': 0,\n",
       " 'fail': 0,\n",
       " 'word': 0,\n",
       " 'critic': 0,\n",
       " 'ineffici': 0,\n",
       " 'use': 0,\n",
       " 'fuller': 0,\n",
       " 'member': 0,\n",
       " 'immens': 0,\n",
       " 'public': 1,\n",
       " 'first': 0,\n",
       " 'tuesday': 1,\n",
       " 'footag': 1,\n",
       " 'firm': 0,\n",
       " 'month': 0,\n",
       " 'innov': 0,\n",
       " 'outsid': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>agent</th>\n",
       "      <th>aggrav</th>\n",
       "      <th>amazon</th>\n",
       "      <th>anoth</th>\n",
       "      <th>...</th>\n",
       "      <th>various</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>welcom</th>\n",
       "      <th>west</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yorkshir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstain  achiev  action  activist  adopt  affair  agent  aggrav  amazon  \\\n",
       "0        1       1       1         0      1       1      0       0       1   \n",
       "1        0       0       0         1      0       0      1       1       0   \n",
       "\n",
       "   anoth    ...     various  vocal  vote  welcom  west  without  word  would  \\\n",
       "0      0    ...           0      1     1       1     0        1     1      3   \n",
       "1      1    ...           1      0     0       0     2        0     0      0   \n",
       "\n",
       "   year  yorkshir  \n",
       "0     0         0  \n",
       "1     2         2  \n",
       "\n",
       "[2 rows x 203 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([wordDictA, wordDictB])\n",
    "df.reindex(sorted(df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>agent</th>\n",
       "      <th>aggrav</th>\n",
       "      <th>amazon</th>\n",
       "      <th>anoth</th>\n",
       "      <th>...</th>\n",
       "      <th>various</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>welcom</th>\n",
       "      <th>west</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yorkshir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstain  achiev  action  activist  adopt  affair  agent  aggrav  amazon  \\\n",
       "0        1       1       1         0      1       1      0       0       1   \n",
       "1        0       0       0         1      0       0      1       1       0   \n",
       "\n",
       "   anoth    ...     various  vocal  vote  welcom  west  without  word  would  \\\n",
       "0      0    ...           0      1     1       1     0        1     1      3   \n",
       "1      1    ...           1      0     0       0     2        0     0      0   \n",
       "\n",
       "   year  yorkshir  \n",
       "0     0         0  \n",
       "1     2         2  \n",
       "\n",
       "[2 rows x 203 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_a = ' '.join(arta_stemmed)\n",
    "cleaned_b = ' '.join(artb_stemmed)\n",
    "\n",
    "counts = sklearn.feature_extraction.text.CountVectorizer()\n",
    "counts_fitted = counts.fit_transform([cleaned_a, cleaned_b])\n",
    "\n",
    "pd.DataFrame(counts_fitted.toarray(), columns=counts.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / bowCount\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfbowA = computeTF(wordDictA, arta_stemmed)\n",
    "tfbowB = computeTF(wordDictB, artb_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 0.005434782608695652,\n",
       " 'bnp': 0.0,\n",
       " 'commit': 0.0,\n",
       " 'bbc': 0.0,\n",
       " 'juli': 0.0,\n",
       " 'conspiraci': 0.0,\n",
       " 'gain': 0.005434782608695652,\n",
       " 'put': 0.005434782608695652,\n",
       " 'hold': 0.005434782608695652,\n",
       " 'us': 0.016304347826086956,\n",
       " 'intend': 0.005434782608695652,\n",
       " 'start': 0.005434782608695652,\n",
       " 'brighton': 0.0,\n",
       " 'propos': 0.010869565217391304,\n",
       " 'inquiri': 0.0,\n",
       " 'covert': 0.0,\n",
       " 'draft': 0.016304347826086956,\n",
       " 'men': 0.0,\n",
       " 'lancashir': 0.0,\n",
       " 'arrest': 0.0,\n",
       " 'detain': 0.0,\n",
       " 'leader': 0.0,\n",
       " 'agent': 0.0,\n",
       " 'chairman': 0.0,\n",
       " 'bring': 0.005434782608695652,\n",
       " 'model': 0.005434782608695652,\n",
       " 'nation': 0.005434782608695652,\n",
       " 'comput': 0.021739130434782608,\n",
       " 'achiev': 0.005434782608695652,\n",
       " 'meet': 0.005434782608695652,\n",
       " 'pressur': 0.005434782608695652,\n",
       " 'hatr': 0.0,\n",
       " 'poland': 0.005434782608695652,\n",
       " 'support': 0.010869565217391304,\n",
       " 'john': 0.0,\n",
       " 'septemb': 0.0,\n",
       " 'british': 0.0,\n",
       " 'reject': 0.005434782608695652,\n",
       " 'bail': 0.0,\n",
       " 'click': 0.005434782608695652,\n",
       " 'burnley': 0.0,\n",
       " 'compani': 0.005434782608695652,\n",
       " 'leicest': 0.0,\n",
       " 'griffin': 0.0,\n",
       " 'new': 0.010869565217391304,\n",
       " 'welcom': 0.005434782608695652,\n",
       " 'sunday': 0.0,\n",
       " 'crimin': 0.0,\n",
       " 'freed': 0.0,\n",
       " 'lead': 0.005434782608695652,\n",
       " 'seven': 0.0,\n",
       " 'screen': 0.0,\n",
       " 'parti': 0.0,\n",
       " 'sourc': 0.005434782608695652,\n",
       " 'area': 0.0,\n",
       " 'part': 0.0,\n",
       " 'develop': 0.005434782608695652,\n",
       " 'rule': 0.005434782608695652,\n",
       " 'issu': 0.005434782608695652,\n",
       " 'base': 0.010869565217391304,\n",
       " 'larger': 0.005434782608695652,\n",
       " 'mep': 0.010869565217391304,\n",
       " 'activist': 0.0,\n",
       " 'west': 0.0,\n",
       " 'field': 0.005434782608695652,\n",
       " 'direct': 0.021739130434782608,\n",
       " 'union': 0.005434782608695652,\n",
       " 'amazon': 0.005434782608695652,\n",
       " 'committe': 0.010869565217391304,\n",
       " 'suspicion': 0.0,\n",
       " 'could': 0.016304347826086956,\n",
       " 'fight': 0.005434782608695652,\n",
       " 'documentari': 0.0,\n",
       " 'confirm': 0.0,\n",
       " 'rewrit': 0.005434782608695652,\n",
       " 'order': 0.010869565217391304,\n",
       " 'racial': 0.0,\n",
       " 'incit': 0.0,\n",
       " 'court': 0.005434782608695652,\n",
       " 'decis': 0.005434782608695652,\n",
       " 'happen': 0.005434782608695652,\n",
       " 'protect': 0.010869565217391304,\n",
       " 'servic': 0.005434782608695652,\n",
       " 'hurt': 0.005434782608695652,\n",
       " 'charg': 0.0,\n",
       " 'effect': 0.005434782608695652,\n",
       " 'yorkshir': 0.0,\n",
       " 'say': 0.016304347826086956,\n",
       " 'impact': 0.005434782608695652,\n",
       " 'offer': 0.005434782608695652,\n",
       " 'secret': 0.0,\n",
       " 'said': 0.010869565217391304,\n",
       " 'submit': 0.005434782608695652,\n",
       " 'line': 0.005434782608695652,\n",
       " 'implic': 0.005434782608695652,\n",
       " 'intens': 0.005434782608695652,\n",
       " 'keighley': 0.0,\n",
       " 'lobbi': 0.005434782608695652,\n",
       " 'give': 0.005434782608695652,\n",
       " 'adopt': 0.005434782608695652,\n",
       " 'serv': 0.005434782608695652,\n",
       " 'even': 0.005434782608695652,\n",
       " 'old': 0.0,\n",
       " 'anoth': 0.0,\n",
       " 'nick': 0.0,\n",
       " 'legal': 0.016304347826086956,\n",
       " 'busi': 0.005434782608695652,\n",
       " 'larg': 0.005434782608695652,\n",
       " 'play': 0.005434782608695652,\n",
       " 'morn': 0.0,\n",
       " 'debat': 0.005434782608695652,\n",
       " 'controversi': 0.005434782608695652,\n",
       " 'various': 0.0,\n",
       " 'suffer': 0.005434782608695652,\n",
       " 'possess': 0.0,\n",
       " 'two': 0.010869565217391304,\n",
       " 'spokesperson': 0.0,\n",
       " 'offenc': 0.0,\n",
       " 'back': 0.010869565217391304,\n",
       " 'read': 0.005434782608695652,\n",
       " 'twelfth': 0.0,\n",
       " 'damag': 0.0,\n",
       " 'favour': 0.005434782608695652,\n",
       " 'current': 0.005434782608695652,\n",
       " 'exampl': 0.005434782608695652,\n",
       " 'would': 0.016304347826086956,\n",
       " 'vote': 0.005434782608695652,\n",
       " 'largest': 0.005434782608695652,\n",
       " 'parliament': 0.010869565217391304,\n",
       " 'program': 0.005434782608695652,\n",
       " 'reboot': 0.005434782608695652,\n",
       " 'europ': 0.005434782608695652,\n",
       " 'firearm': 0.0,\n",
       " 'monday': 0.0,\n",
       " 'vocal': 0.005434782608695652,\n",
       " 'nine': 0.0,\n",
       " 'small': 0.010869565217391304,\n",
       " 'connect': 0.0,\n",
       " 'might': 0.005434782608695652,\n",
       " 'patent': 0.02717391304347826,\n",
       " 'com': 0.005434782608695652,\n",
       " 'law': 0.02717391304347826,\n",
       " 'suspect': 0.0,\n",
       " 'releas': 0.0,\n",
       " 'european': 0.010869565217391304,\n",
       " 'eu': 0.021739130434782608,\n",
       " 'polic': 0.0,\n",
       " 'abstain': 0.005434782608695652,\n",
       " 'let': 0.005434782608695652,\n",
       " 'found': 0.0,\n",
       " 'chanc': 0.005434782608695652,\n",
       " 'featur': 0.0,\n",
       " 'mean': 0.005434782608695652,\n",
       " 'without': 0.005434782608695652,\n",
       " 'setback': 0.005434782608695652,\n",
       " 'aggrav': 0.0,\n",
       " 'year': 0.0,\n",
       " 'permit': 0.005434782608695652,\n",
       " 'mr': 0.0,\n",
       " 'tyndal': 0.0,\n",
       " 'man': 0.0,\n",
       " 'concern': 0.005434782608695652,\n",
       " 'implement': 0.010869565217391304,\n",
       " 'commiss': 0.005434782608695652,\n",
       " 'method': 0.005434782608695652,\n",
       " 'shop': 0.005434782608695652,\n",
       " 'speech': 0.0,\n",
       " 'similar': 0.005434782608695652,\n",
       " 'juri': 0.010869565217391304,\n",
       " 'internet': 0.005434782608695652,\n",
       " 'follow': 0.0,\n",
       " 'one': 0.016304347826086956,\n",
       " 'open': 0.005434782608695652,\n",
       " 'financi': 0.005434782608695652,\n",
       " 'state': 0.010869565217391304,\n",
       " 'spokesman': 0.0,\n",
       " 'held': 0.0,\n",
       " 'affair': 0.005434782608695652,\n",
       " 'oppon': 0.005434782608695652,\n",
       " 'momentum': 0.005434782608695652,\n",
       " 'invent': 0.02717391304347826,\n",
       " 'film': 0.0,\n",
       " 'twice': 0.005434782608695652,\n",
       " 'govern': 0.005434782608695652,\n",
       " 'softwar': 0.016304347826086956,\n",
       " 'made': 0.0,\n",
       " 'fear': 0.005434782608695652,\n",
       " 'fail': 0.005434782608695652,\n",
       " 'word': 0.005434782608695652,\n",
       " 'critic': 0.010869565217391304,\n",
       " 'ineffici': 0.005434782608695652,\n",
       " 'use': 0.005434782608695652,\n",
       " 'fuller': 0.005434782608695652,\n",
       " 'member': 0.010869565217391304,\n",
       " 'immens': 0.005434782608695652,\n",
       " 'public': 0.0,\n",
       " 'first': 0.005434782608695652,\n",
       " 'tuesday': 0.0,\n",
       " 'footag': 0.0,\n",
       " 'firm': 0.010869565217391304,\n",
       " 'month': 0.005434782608695652,\n",
       " 'innov': 0.005434782608695652,\n",
       " 'outsid': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfbowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    \"\"\" compute inverse doc freq for each doc in the docList\n",
    "    returns: IDF for each doc\n",
    "    \"\"\"\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / val)\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 0.6931471805599453,\n",
       " 'bnp': 0.6931471805599453,\n",
       " 'commit': 0.6931471805599453,\n",
       " 'bbc': 0.6931471805599453,\n",
       " 'juli': 0.6931471805599453,\n",
       " 'conspiraci': 0.6931471805599453,\n",
       " 'gain': 0.6931471805599453,\n",
       " 'put': 0.6931471805599453,\n",
       " 'hold': 0.6931471805599453,\n",
       " 'us': 0.6931471805599453,\n",
       " 'intend': 0.6931471805599453,\n",
       " 'start': 0.6931471805599453,\n",
       " 'brighton': 0.6931471805599453,\n",
       " 'propos': 0.6931471805599453,\n",
       " 'inquiri': 0.6931471805599453,\n",
       " 'covert': 0.6931471805599453,\n",
       " 'draft': 0.6931471805599453,\n",
       " 'men': 0.6931471805599453,\n",
       " 'lancashir': 0.6931471805599453,\n",
       " 'arrest': 0.6931471805599453,\n",
       " 'detain': 0.6931471805599453,\n",
       " 'leader': 0.6931471805599453,\n",
       " 'agent': 0.6931471805599453,\n",
       " 'chairman': 0.6931471805599453,\n",
       " 'bring': 0.6931471805599453,\n",
       " 'model': 0.6931471805599453,\n",
       " 'nation': 0.0,\n",
       " 'comput': 0.6931471805599453,\n",
       " 'achiev': 0.6931471805599453,\n",
       " 'meet': 0.6931471805599453,\n",
       " 'pressur': 0.6931471805599453,\n",
       " 'hatr': 0.6931471805599453,\n",
       " 'poland': 0.6931471805599453,\n",
       " 'support': 0.6931471805599453,\n",
       " 'john': 0.6931471805599453,\n",
       " 'septemb': 0.6931471805599453,\n",
       " 'british': 0.6931471805599453,\n",
       " 'reject': 0.6931471805599453,\n",
       " 'bail': 0.6931471805599453,\n",
       " 'click': 0.6931471805599453,\n",
       " 'burnley': 0.6931471805599453,\n",
       " 'compani': 0.6931471805599453,\n",
       " 'leicest': 0.6931471805599453,\n",
       " 'griffin': 0.6931471805599453,\n",
       " 'new': 0.6931471805599453,\n",
       " 'welcom': 0.6931471805599453,\n",
       " 'sunday': 0.6931471805599453,\n",
       " 'crimin': 0.6931471805599453,\n",
       " 'freed': 0.6931471805599453,\n",
       " 'lead': 0.6931471805599453,\n",
       " 'seven': 0.6931471805599453,\n",
       " 'screen': 0.6931471805599453,\n",
       " 'parti': 0.6931471805599453,\n",
       " 'sourc': 0.6931471805599453,\n",
       " 'area': 0.6931471805599453,\n",
       " 'part': 0.6931471805599453,\n",
       " 'develop': 0.6931471805599453,\n",
       " 'rule': 0.6931471805599453,\n",
       " 'issu': 0.6931471805599453,\n",
       " 'base': 0.6931471805599453,\n",
       " 'larger': 0.6931471805599453,\n",
       " 'mep': 0.6931471805599453,\n",
       " 'activist': 0.6931471805599453,\n",
       " 'west': 0.6931471805599453,\n",
       " 'field': 0.6931471805599453,\n",
       " 'direct': 0.6931471805599453,\n",
       " 'union': 0.6931471805599453,\n",
       " 'amazon': 0.6931471805599453,\n",
       " 'committe': 0.6931471805599453,\n",
       " 'suspicion': 0.6931471805599453,\n",
       " 'could': 0.6931471805599453,\n",
       " 'fight': 0.6931471805599453,\n",
       " 'documentari': 0.6931471805599453,\n",
       " 'confirm': 0.6931471805599453,\n",
       " 'rewrit': 0.6931471805599453,\n",
       " 'order': 0.0,\n",
       " 'racial': 0.6931471805599453,\n",
       " 'incit': 0.6931471805599453,\n",
       " 'court': 0.6931471805599453,\n",
       " 'decis': 0.6931471805599453,\n",
       " 'happen': 0.6931471805599453,\n",
       " 'protect': 0.6931471805599453,\n",
       " 'servic': 0.6931471805599453,\n",
       " 'hurt': 0.6931471805599453,\n",
       " 'charg': 0.6931471805599453,\n",
       " 'effect': 0.6931471805599453,\n",
       " 'yorkshir': 0.6931471805599453,\n",
       " 'say': 0.6931471805599453,\n",
       " 'impact': 0.6931471805599453,\n",
       " 'offer': 0.6931471805599453,\n",
       " 'secret': 0.6931471805599453,\n",
       " 'said': 0.0,\n",
       " 'submit': 0.6931471805599453,\n",
       " 'line': 0.6931471805599453,\n",
       " 'implic': 0.6931471805599453,\n",
       " 'intens': 0.6931471805599453,\n",
       " 'keighley': 0.6931471805599453,\n",
       " 'lobbi': 0.6931471805599453,\n",
       " 'give': 0.6931471805599453,\n",
       " 'adopt': 0.6931471805599453,\n",
       " 'serv': 0.6931471805599453,\n",
       " 'even': 0.6931471805599453,\n",
       " 'old': 0.6931471805599453,\n",
       " 'anoth': 0.6931471805599453,\n",
       " 'nick': 0.6931471805599453,\n",
       " 'legal': 0.6931471805599453,\n",
       " 'busi': 0.6931471805599453,\n",
       " 'larg': 0.6931471805599453,\n",
       " 'play': 0.6931471805599453,\n",
       " 'morn': 0.6931471805599453,\n",
       " 'debat': 0.6931471805599453,\n",
       " 'controversi': 0.6931471805599453,\n",
       " 'various': 0.6931471805599453,\n",
       " 'suffer': 0.6931471805599453,\n",
       " 'possess': 0.6931471805599453,\n",
       " 'two': 0.0,\n",
       " 'spokesperson': 0.6931471805599453,\n",
       " 'offenc': 0.6931471805599453,\n",
       " 'back': 0.6931471805599453,\n",
       " 'read': 0.6931471805599453,\n",
       " 'twelfth': 0.6931471805599453,\n",
       " 'damag': 0.6931471805599453,\n",
       " 'favour': 0.6931471805599453,\n",
       " 'current': 0.6931471805599453,\n",
       " 'exampl': 0.6931471805599453,\n",
       " 'would': 0.6931471805599453,\n",
       " 'vote': 0.6931471805599453,\n",
       " 'largest': 0.6931471805599453,\n",
       " 'parliament': 0.6931471805599453,\n",
       " 'program': 0.6931471805599453,\n",
       " 'reboot': 0.6931471805599453,\n",
       " 'europ': 0.6931471805599453,\n",
       " 'firearm': 0.6931471805599453,\n",
       " 'monday': 0.6931471805599453,\n",
       " 'vocal': 0.6931471805599453,\n",
       " 'nine': 0.6931471805599453,\n",
       " 'small': 0.6931471805599453,\n",
       " 'connect': 0.6931471805599453,\n",
       " 'might': 0.6931471805599453,\n",
       " 'patent': 0.6931471805599453,\n",
       " 'com': 0.6931471805599453,\n",
       " 'law': 0.6931471805599453,\n",
       " 'suspect': 0.6931471805599453,\n",
       " 'releas': 0.6931471805599453,\n",
       " 'european': 0.6931471805599453,\n",
       " 'eu': 0.6931471805599453,\n",
       " 'polic': 0.6931471805599453,\n",
       " 'abstain': 0.6931471805599453,\n",
       " 'let': 0.6931471805599453,\n",
       " 'found': 0.6931471805599453,\n",
       " 'chanc': 0.6931471805599453,\n",
       " 'featur': 0.6931471805599453,\n",
       " 'mean': 0.6931471805599453,\n",
       " 'without': 0.6931471805599453,\n",
       " 'setback': 0.6931471805599453,\n",
       " 'aggrav': 0.6931471805599453,\n",
       " 'year': 0.6931471805599453,\n",
       " 'permit': 0.6931471805599453,\n",
       " 'mr': 0.6931471805599453,\n",
       " 'tyndal': 0.6931471805599453,\n",
       " 'man': 0.6931471805599453,\n",
       " 'concern': 0.6931471805599453,\n",
       " 'implement': 0.6931471805599453,\n",
       " 'commiss': 0.6931471805599453,\n",
       " 'method': 0.6931471805599453,\n",
       " 'shop': 0.6931471805599453,\n",
       " 'speech': 0.6931471805599453,\n",
       " 'similar': 0.6931471805599453,\n",
       " 'juri': 0.6931471805599453,\n",
       " 'internet': 0.6931471805599453,\n",
       " 'follow': 0.6931471805599453,\n",
       " 'one': 0.6931471805599453,\n",
       " 'open': 0.6931471805599453,\n",
       " 'financi': 0.6931471805599453,\n",
       " 'state': 0.6931471805599453,\n",
       " 'spokesman': 0.6931471805599453,\n",
       " 'held': 0.6931471805599453,\n",
       " 'affair': 0.6931471805599453,\n",
       " 'oppon': 0.6931471805599453,\n",
       " 'momentum': 0.6931471805599453,\n",
       " 'invent': 0.6931471805599453,\n",
       " 'film': 0.6931471805599453,\n",
       " 'twice': 0.6931471805599453,\n",
       " 'govern': 0.6931471805599453,\n",
       " 'softwar': 0.6931471805599453,\n",
       " 'made': 0.6931471805599453,\n",
       " 'fear': 0.6931471805599453,\n",
       " 'fail': 0.6931471805599453,\n",
       " 'word': 0.6931471805599453,\n",
       " 'critic': 0.6931471805599453,\n",
       " 'ineffici': 0.6931471805599453,\n",
       " 'use': 0.6931471805599453,\n",
       " 'fuller': 0.6931471805599453,\n",
       " 'member': 0.6931471805599453,\n",
       " 'immens': 0.6931471805599453,\n",
       " 'public': 0.6931471805599453,\n",
       " 'first': 0.6931471805599453,\n",
       " 'tuesday': 0.6931471805599453,\n",
       " 'footag': 0.6931471805599453,\n",
       " 'firm': 0.6931471805599453,\n",
       " 'month': 0.6931471805599453,\n",
       " 'innov': 0.6931471805599453,\n",
       " 'outsid': 0.6931471805599453}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    \"\"\"creates function for computing TFIDF\"\"\"\n",
    "    tfidf = {} # creates empty dictionary\n",
    "    for word, val in tfBow.items(): #starts a for loop using keys (word) and values from tfBow\n",
    "        tfidf[word] = val * idfs[word] #for each word in tfBow, the value is multiplied by the idfs for the word. \n",
    "                                        #The word and resulting computation are then added to the dictionary tfidf\n",
    "    return tfidf #returns the dictionary tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfBowA = computeTFIDF(tfbowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfbowB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>agent</th>\n",
       "      <th>aggrav</th>\n",
       "      <th>amazon</th>\n",
       "      <th>anoth</th>\n",
       "      <th>...</th>\n",
       "      <th>various</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>welcom</th>\n",
       "      <th>west</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yorkshir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.010746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstain    achiev    action  activist     adopt    affair     agent  \\\n",
       "0  0.003767  0.003767  0.003767  0.000000  0.003767  0.003767  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.005373  0.000000  0.000000  0.005373   \n",
       "\n",
       "     aggrav    amazon     anoth    ...      various     vocal      vote  \\\n",
       "0  0.000000  0.003767  0.000000    ...     0.000000  0.003767  0.003767   \n",
       "1  0.005373  0.000000  0.005373    ...     0.005373  0.000000  0.000000   \n",
       "\n",
       "     welcom      west   without      word     would      year  yorkshir  \n",
       "0  0.003767  0.000000  0.003767  0.003767  0.011301  0.000000  0.000000  \n",
       "1  0.000000  0.010746  0.000000  0.000000  0.000000  0.010746  0.010746  \n",
       "\n",
       "[2 rows x 203 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nlpbh = pd.DataFrame([tfidfBowA, tfidfBowB])\n",
    "nlpbh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>agent</th>\n",
       "      <th>aggrav</th>\n",
       "      <th>amazon</th>\n",
       "      <th>anoth</th>\n",
       "      <th>...</th>\n",
       "      <th>various</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>welcom</th>\n",
       "      <th>west</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yorkshir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>0.157768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056655</td>\n",
       "      <td>0.056655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113311</td>\n",
       "      <td>0.113311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstain    achiev    action  activist     adopt    affair     agent  \\\n",
       "0  0.052589  0.052589  0.052589  0.000000  0.052589  0.052589  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.056655  0.000000  0.000000  0.056655   \n",
       "\n",
       "     aggrav    amazon     anoth    ...      various     vocal      vote  \\\n",
       "0  0.000000  0.052589  0.000000    ...     0.000000  0.052589  0.052589   \n",
       "1  0.056655  0.000000  0.056655    ...     0.056655  0.000000  0.000000   \n",
       "\n",
       "     welcom      west   without      word     would      year  yorkshir  \n",
       "0  0.052589  0.000000  0.052589  0.052589  0.157768  0.000000  0.000000  \n",
       "1  0.000000  0.113311  0.000000  0.000000  0.000000  0.113311  0.113311  \n",
       "\n",
       "[2 rows x 203 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a string again\n",
    "cleaned_a = ' '.join(arta_stemmed)\n",
    "cleaned_b = ' '.join(artb_stemmed)\n",
    "\n",
    "\n",
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "response = tfidf.fit_transform([cleaned_a, cleaned_b])\n",
    "\n",
    "nlpskl = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())\n",
    "nlpskl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that these values are different! Sklearn's formula for tf-idf is a little more sophisticated than ours. See the doc for the transformer [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams\n",
    "\n",
    "Notice that the `TfidfVectorizer()` has a parameter called \"ngram_range\". Sometimes we want to search not only for individual words but for pairs or triples (etc.) of words. Using $N$ as a variable for the size of the word cluster to consider, we speak of \"N-grams\". Notice that our default is (1, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.      , 0.013575],\n",
       "       [0.013575, 1.      ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.pairwise.cosine_similarity(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Modeling\n",
    "\n",
    "Naive Bayes models lend themselves well to NLP problems. Consider the task of trying to predict genre from text. My subjective probability that a text belongs to a certain genre would be a function of the words in the text. So e.g. the (prior) probability that a text is science-fiction may be relatively small. But the probability that a text is science-fiction *given that it uses the word 'cyclotron'* may be quite high.\n",
    "\n",
    "Now: What's \"naive\" about Naive Bayes models?\n",
    "\n",
    "The calculation of the relevant probabilities could get very complicated. But they get much simpler with the (relatively implausible!) assumption that the different features (occurrences of particular words, in our present case of NLP) are *independent*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_20newsgroups().target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(subset='train')\n",
    "test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = count.fit_transform(train.data)\n",
    "X_test = count.transform(test.data)\n",
    "y_train = train.target\n",
    "y_test = test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  5,  0, 17, 19, 13, 15, 15,  5,  1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which NB model do you want? Check out the options and their differences [here](https://scikit-learn.org/stable/modules/naive_bayes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8023101433882103"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[257,   0,   0,   2,   0,   1,   0,   0,   1,   1,   2,   1,   1,\n",
       "          6,   3,  27,   3,   6,   3,   5],\n",
       "       [  1, 310,   0,  14,   6,  22,   1,   0,   0,   2,   0,  12,   7,\n",
       "          2,   7,   0,   1,   1,   3,   0],\n",
       "       [  1,  67,  16, 145,  15,  93,   3,   1,   4,   4,   1,  17,   3,\n",
       "          2,   8,   1,   1,   1,  10,   1],\n",
       "       [  0,  11,   1, 313,  16,  10,   6,   3,   1,   0,   1,   4,  21,\n",
       "          0,   5,   0,   0,   0,   0,   0],\n",
       "       [  0,  13,   1,  20, 306,   6,   6,   4,   2,   2,   0,   4,  11,\n",
       "          3,   3,   0,   2,   0,   2,   0],\n",
       "       [  1,  34,   2,  11,   1, 332,   0,   0,   0,   0,   0,   6,   0,\n",
       "          2,   4,   0,   2,   0,   0,   0],\n",
       "       [  0,   3,   0,  31,  13,   3, 288,  15,   3,   1,   6,   0,  12,\n",
       "          7,   3,   0,   2,   1,   2,   0],\n",
       "       [  0,   1,   0,   2,   0,   0,   5, 364,   4,   1,   2,   1,   5,\n",
       "          1,   3,   0,   2,   1,   4,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   3,  10, 375,   0,   0,   1,   2,\n",
       "          0,   0,   0,   1,   0,   5,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   1,   4,   0, 364,  18,   0,   0,\n",
       "          0,   2,   0,   2,   2,   3,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   5, 387,   1,   0,\n",
       "          1,   1,   1,   0,   0,   3,   0],\n",
       "       [  0,   2,   0,   0,   0,   2,   2,   1,   0,   0,   0, 379,   2,\n",
       "          2,   3,   0,   2,   0,   1,   0],\n",
       "       [  0,  18,   0,  26,   4,   4,   6,   3,   2,   0,   0,  35, 275,\n",
       "          9,   5,   1,   0,   2,   3,   0],\n",
       "       [  5,   7,   0,   2,   0,   1,   2,   1,   0,   2,   1,   1,   5,\n",
       "        343,   5,   5,   2,   4,  10,   0],\n",
       "       [  2,   6,   0,   0,   0,   3,   0,   1,   0,   0,   0,   1,   2,\n",
       "          4, 364,   1,   1,   1,   8,   0],\n",
       "       [  4,   2,   0,   1,   0,   1,   0,   0,   0,   0,   1,   0,   1,\n",
       "          3,   2, 377,   0,   0,   1,   5],\n",
       "       [  0,   1,   0,   1,   0,   0,   2,   0,   2,   1,   0,   5,   0,\n",
       "          0,   0,   0, 337,   1,  13,   1],\n",
       "       [  4,   1,   0,   0,   0,   2,   0,   0,   0,   1,   0,   3,   0,\n",
       "          1,   0,   1,   2, 353,   8,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,   1,   0,   0,   1,   3,   0,\n",
       "          3,  11,   1,  89,   3, 193,   3],\n",
       "       [ 44,   2,   0,   0,   0,   1,   0,   0,   0,   0,   1,   1,   0,\n",
       "          3,   4,  50,  22,   3,  10, 110]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Statistics \n",
    "\n",
    "How many non-zero elements are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 103.5\n",
      "Percentage of columns containing 0: 0.6896551724137931\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "newval = np.array(df)\n",
    "\n",
    "non_zero_vals = np.count_nonzero(newval) / float(df.shape[0])\n",
    "print(f'Average Number of Non-Zero Elements in Vectorized Articles: {non_zero_vals}')\n",
    "\n",
    "percent_sparse = len([col for col in df.columns if sum(df[col]) <= 1]) / df.shape[1]\n",
    "print(f'Percentage of columns containing 0: {percent_sparse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "- Create the tf-idf for the **whole** corpus of 12 articles\n",
    "- What are _on average_ the most important words in the whole corpus?\n",
    "- Add a column named \"Target\" to the dataset\n",
    "- Target will be set to 1 or 0 if the article is \"Politics\" or \"Not Politics\"\n",
    "- Do some exploratory analysis of the dataset\n",
    " - What are the average most important words for the \"Politics\" articles?\n",
    " - What are the average most important words for the \"Not Politics\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets talk classification\n",
    "- How would you split into train and test? what would be the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
